{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32a41ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader=PyPDFLoader(file_path=r'C:\\Users\\Vishnu\\Desktop\\AI-Powered_Job_Reccomendation\\Vishnu_B_DS_AlmaBetter.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bb650b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e64d05fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationdate': '2025-05-12T22:45:16+00:00', 'moddate': '2025-05-12T22:45:16+00:00', 'source': 'C:\\\\Users\\\\Vishnu\\\\Desktop\\\\AI-Powered_Job_Reccomendation\\\\Vishnu_B_DS_AlmaBetter.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96c114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_perplexity import ChatPerplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38643519",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key_groq = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = api_key_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1369fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "\n",
    "# api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22125742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatModel - GROQ\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fd00a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a resume parser AI assistant.\n",
    "\n",
    "Extract the following information from the provided resume and return it in **valid JSON format only** (no extra text):\n",
    "- location (city, state/country if available)\n",
    "- job_title (list all job titles)\n",
    "- experience_years (approximate total)\n",
    "- skills (list all technical skills)\n",
    "- education (degree, major, and university)\n",
    "- certifications (if any)\n",
    "- preferred_job_type (e.g., Full-time, Internship, Remote)\n",
    "\n",
    "Resume:\n",
    "\\\"\\\"\\\"\n",
    "{docs}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Respond with JSON only, no explanation or text outside the JSON block.\n",
    "\"\"\"\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e05945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser\n",
    "parser= JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first chain\n",
    "chain = template | model | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3ff2e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': {'city': 'Noida', 'state': 'Not specified', 'country': 'Not specified'}, 'job_titles': ['Team Leader - Operations', 'Data Science Trainee', 'Teaching Assistant'], 'experience_years': 5, 'skills': ['Python', 'SQL', 'Excel', 'Tableau', 'Power BI', 'Git', 'Jupyter Notebook', 'Google Colab', 'PostgreSQL', 'Visual Studio Code', 'Pandas', 'NumPy', 'Matplotlib', 'Seaborn', 'Scikit-Learn', 'NLTK', 'K-Means Clustering', 'Machine Learning', 'Financial Analysis', 'Logistic Regression', 'Decision Tree', 'Random Forest', 'Naive Bayes', 'TF-IDF', 'Power Query', 'DAX', 'Data Modeling'], 'education': {'degree': 'B.Tech', 'major': 'Mechanical Engineering', 'university': 'Deenbandhu Chhotu Ram University of Science and Technology'}, 'certifications': ['Advanced Certification in Full Stack Data Science & AI', 'Microsoft Excel - Excel from Beginner to Advanced', 'SQL (Advanced) Certificate'], 'preferred_job_type': 'Full-time'}\n"
     ]
    }
   ],
   "source": [
    "extracted_data = chain.invoke(docs)\n",
    "\n",
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7eeceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the resume JSON into a single string of text\n",
    "def convert_resume_to_text(resume_data):\n",
    "    resume_text = (\n",
    "        f\"Location: {resume_data['location']}\\n\"\n",
    "        f\"Job Titles: {', '.join(resume_data['job_titles'])}\\n\"\n",
    "        f\"Experience Years: {resume_data['experience_years']}\\n\"\n",
    "        f\"Skills: {', '.join(resume_data['skills'])}\\n\"\n",
    "        f\"Education: {resume_data['education']['degree']} in {resume_data['education']['major']} from {resume_data['education']['university']}\\n\"\n",
    "        f\"Certifications: {', '.join(resume_data['certifications'])}\\n\"\n",
    "        f\"Preferred Job Type: {resume_data['preferred_job_type']}\"\n",
    "    )\n",
    "    return resume_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resume_text = convert_resume_to_text(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cf85b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': {'city': 'Noida',\n",
       "  'state': 'Not specified',\n",
       "  'country': 'Not specified'},\n",
       " 'job_titles': ['Team Leader - Operations',\n",
       "  'Data Science Trainee',\n",
       "  'Teaching Assistant'],\n",
       " 'experience_years': 5,\n",
       " 'skills': ['Python',\n",
       "  'SQL',\n",
       "  'Excel',\n",
       "  'Tableau',\n",
       "  'Power BI',\n",
       "  'Git',\n",
       "  'Jupyter Notebook',\n",
       "  'Google Colab',\n",
       "  'PostgreSQL',\n",
       "  'Visual Studio Code',\n",
       "  'Pandas',\n",
       "  'NumPy',\n",
       "  'Matplotlib',\n",
       "  'Seaborn',\n",
       "  'Scikit-Learn',\n",
       "  'NLTK',\n",
       "  'K-Means Clustering',\n",
       "  'Machine Learning',\n",
       "  'Financial Analysis',\n",
       "  'Logistic Regression',\n",
       "  'Decision Tree',\n",
       "  'Random Forest',\n",
       "  'Naive Bayes',\n",
       "  'TF-IDF',\n",
       "  'Power Query',\n",
       "  'DAX',\n",
       "  'Data Modeling'],\n",
       " 'education': {'degree': 'B.Tech',\n",
       "  'major': 'Mechanical Engineering',\n",
       "  'university': 'Deenbandhu Chhotu Ram University of Science and Technology'},\n",
       " 'certifications': ['Advanced Certification in Full Stack Data Science & AI',\n",
       "  'Microsoft Excel - Excel from Beginner to Advanced',\n",
       "  'SQL (Advanced) Certificate'],\n",
       " 'preferred_job_type': 'Full-time'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded job_title\n",
    "job_title = 'Data Analyst OR Data Scientist OR AI Engineer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca92e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping library\n",
    "import requests\n",
    "\n",
    "url = \"https://jsearch.p.rapidapi.com/search\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Rapid Api to fetch job details\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "querystring = {\"query\":job_title,\"page\":\"1\",\"num_pages\":\"1\",\"country\":\"in\",\"date_posted\":\"3days\"}\n",
    "\n",
    "\n",
    "# Fetching the API key and host from environment variables\n",
    "api_key = os.getenv(\"RAPIDAPI_KEY\")\n",
    "api_host = os.getenv(\"RAPIDAPI_HOST\")\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"x-rapidapi-key\":api_key ,\n",
    "    \"x-rapidapi-host\": api_host\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e441cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be66ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=results['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4068648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_id': '1KrlXuQgUYO3vXs6AAAAAA==',\n",
       " 'job_title': 'Data Scientist â€“ ML / AI-Systems',\n",
       " 'employer_name': 'Illumina',\n",
       " 'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSaTy3QDr3elI3ku5JVQljcFkFg3s3gJCTvodfI&s=0',\n",
       " 'employer_website': 'http://www.illumina.com/',\n",
       " 'job_publisher': 'LinkedIn',\n",
       " 'job_employment_type': 'Fullâ€“time',\n",
       " 'job_employment_types': ['FULLTIME'],\n",
       " 'job_apply_link': 'https://in.linkedin.com/jobs/view/data-scientist-%E2%80%93-ml-ai-systems-at-illumina-4282143418?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
       " 'job_apply_is_direct': False,\n",
       " 'apply_options': [{'publisher': 'LinkedIn',\n",
       "   'apply_link': 'https://in.linkedin.com/jobs/view/data-scientist-%E2%80%93-ml-ai-systems-at-illumina-4282143418?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
       "   'is_direct': False},\n",
       "  {'publisher': 'Workday',\n",
       "   'apply_link': 'https://illumina.wd1.myworkdayjobs.com/th-TH/illumina-careers/job/Data-Scientist---ML---AI-Systems_41131-JOB-1?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
       "   'is_direct': False},\n",
       "  {'publisher': 'Iitjobs',\n",
       "   'apply_link': 'https://www.iitjobs.com/job/data-scientist-with-ml-ops-usa-exl-74985?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
       "   'is_direct': False},\n",
       "  {'publisher': 'JobRxiv',\n",
       "   'apply_link': 'https://jobrxiv.org/job/data-scientist-ml-ai-systems/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
       "   'is_direct': False},\n",
       "  {'publisher': 'Bayt.com',\n",
       "   'apply_link': 'https://www.bayt.com/en/india/jobs/data-scientist-ml-ai-systems-73201019/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
       "   'is_direct': False}],\n",
       " 'job_description': 'What if the work you did every day could impact the lives of people you know? Or all of humanity?\\n\\nAt Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients.\\n\\nWorking at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world changing projects, you will do more and become more than you ever thought possible.\\n\\nPosition Summary\\n\\nWe are seeking a talented and driven Data Scientist to join our dynamic team at Illumina. In this role, you will collaborate with cross-functional teams of scientists, engineers, and bioinformaticians to analyze complex biological data, develop advanced models, and deliver actionable insights that propel Illuminaâ€™s research, development, and commercial objectives. Your work will directly support initiatives across genomics, clinical applications, and product development, helping to shape the future of personalized medicine and health care.\\n\\nKey Responsibilities\\nâ€¢ Design, develop, and implement robust statistical models, machine learning algorithms, and analytical pipelines.\\nâ€¢ Partner with internal teamsâ€”including research, product, informatics, and engineeringâ€”to define project goals, data needs, and analytical approaches that align with Illuminaâ€™s strategic objectives.\\nâ€¢ Apply data mining and predictive modeling techniques to identify patterns, trends, and correlations in diverse datasets (e.g., sequencing data, clinical outcomes, operational metrics).\\nâ€¢ Evaluate and validate model performance, ensuring reproducibility, scalability, and reliability of analytical solutions.\\nâ€¢ Collaborate with software engineers to deploy analytical tools and integrate models into production-grade software platforms for internal and customer-facing applications.\\nâ€¢ Communicate complex data-driven findings clearly and effectively to both technical and non-technical stakeholders through presentations, documentation, and visualizations.\\nâ€¢ Stay current with emerging trends, tools, and best practices in data science, machine learning, and computational biology; continuously seek opportunities to improve processes and outcomes.\\nâ€¢ Contribute to the publication and dissemination of results in peer-reviewed journals, conferences, and internal reports as appropriate.\\nâ€¢ Collaborate with AI-systems designers to implement LLM driven solutions in support of enterprise use cases (LLM driven chatbots)\\n\\nRequired Qualifications\\nâ€¢ Education: Bachelorâ€™s degree in Data Science, Computer Science, Statistics, Mathematics, Bioinformatics, Computational Biology, Engineering, or a closely related field. Masterâ€™s degree or Ph.D. is preferred.\\nâ€¢ Proven experience working with large and complex datasets, with a strong background in data wrangling, statistical analysis, and machine learning.\\nâ€¢ Demonstrated proficiency in at least one major programming language used for data analysis (such as Python, R, or Julia).\\nâ€¢ Experience with cloud computing platforms, including AWS, MS Azure, as well as modern data warehousing solutions such as Snowflake.\\nâ€¢ Familiarity with enterprise data management / data processing tools â€“ Kubernetes, Tableau, Apache\\nâ€¢ Understanding of version control systems, especially Git, for collaborative code development and review.\\nâ€¢ Excellent communication skills, including the ability to translate technical findings into actionable recommendations for diverse audiences.\\nâ€¢ Analytical mindset and a passion for problem-solving in an interdisciplinary, fast-paced environment.\\nâ€¢ Self-motivated, detail-oriented, and able to manage multiple projects concurrently with minimal supervision.\\n\\nPreferred Qualifications\\nâ€¢ Masterâ€™s degree or Ph.D. in a relevant field (Bioinformatics, Computational Biology, Data Science, etc.).\\nâ€¢ Typically requires a Bachelorâ€™s degree and a minimum of 2 years of related experience; or an advanced degree without experience; or equivalent work experience\\nâ€¢ Hands-on experience with genomic data analysis, including familiarity with next-generation sequencing (NGS) platforms, omics data types, and relevant bioinformatics tools.\\nâ€¢ History of contributing to open-source projects or publications in scientific journals.\\nâ€¢ Experience working in highly regulated environments and understanding of data privacy standards (e.g., HIPAA, GDPR) as applied to biological and clinical data.\\nâ€¢ Background in healthcare, life sciences, or biotechnology industry.\\n\\nKey Skills and Competencies\\nâ€¢ Strong foundation in statistics, probability, and experimental design.\\nâ€¢ Expertise in supervised and unsupervised machine learning techniques (e.g., regression, classification, clustering, dimensionality reduction).\\nâ€¢ Comfortable working in a regulated environment and managing code, solution designs within these constraints.\\nâ€¢ Proficiency in data cleaning, preprocessing, and feature engineering for structured and unstructured data.\\nâ€¢ Ability to assess and select appropriate models, evaluate metrics, and iterate solutions using best practices.\\nâ€¢ Capacity to work collaboratively in multidisciplinary teams and adapt to evolving project requirements.\\nâ€¢ Innovative thinker with a desire to apply data science solutions to real-world challenges.\\n\\nWe are a company deeply rooted in belonging, promoting an inclusive environment where employees feel valued and empowered to contribute to our mission. Built on a strong foundation, Illumina has always prioritized openness, collaboration, and seeking alternative perspectives to propel innovation in genomics. We are proud to confirm a zero-net gap in pay, regardless of gender, ethnicity, or race. We also have several Employee Resource Groups (ERG) that deliver career development experiences, increase cultural awareness, and offer opportunities to engage in social responsibility. We are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. Illumina conducts background checks on applicants for whom a conditional offer of employment has been made. Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable local, state, and federal laws. Background check results may potentially result in the withdrawal of a conditional offer of employment. The background check process and any decisions made as a result shall be made in accordance with all applicable local, state, and federal laws. Illumina prohibits the use of generative artificial intelligence (AI) in the application and interview process. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. The position will be posted until a final candidate is selected or the requisition has a sufficient number of qualified applicants. This role is not eligible for visa sponsorship.',\n",
       " 'job_is_remote': False,\n",
       " 'job_posted_at': '3 days ago',\n",
       " 'job_posted_at_timestamp': 1754611200,\n",
       " 'job_posted_at_datetime_utc': '2025-08-08T00:00:00.000Z',\n",
       " 'job_location': 'India',\n",
       " 'job_city': None,\n",
       " 'job_state': None,\n",
       " 'job_country': 'IN',\n",
       " 'job_latitude': 20.593684,\n",
       " 'job_longitude': 78.96288,\n",
       " 'job_benefits': None,\n",
       " 'job_google_link': 'https://www.google.com/search?q=jobs&gl=in&hl=en&udm=8#vhid=vt%3D20/docid%3D1KrlXuQgUYO3vXs6AAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
       " 'job_salary': None,\n",
       " 'job_min_salary': None,\n",
       " 'job_max_salary': None,\n",
       " 'job_salary_period': None,\n",
       " 'job_highlights': {},\n",
       " 'job_onet_soc': '15111100',\n",
       " 'job_onet_job_zone': '5'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting job records to Documents from json\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def jobs_to_documents(jobs_json):\n",
    "    documents = []\n",
    "    \n",
    "    for job in jobs_json:\n",
    "        text = (\n",
    "            f\"Job Title: {job.get('job_title', '')}\\n\"\n",
    "            f\"Company: {job.get('employer_name', '')}\\n\"\n",
    "            f\"Location: {job.get('job_city', '')}, {job.get('job_country', '')}\\n\"\n",
    "            f\"Description: {job.get('job_description', '')}\\n\"\n",
    "            f\"Qualifications: {job.get('job_highlights', {}).get('Qualifications', '')}\\n\"\n",
    "        )\n",
    "        \n",
    "        metadata = {\n",
    "            \"job_id\": job.get(\"job_id\", \"\"),\n",
    "            \"company\": job.get(\"employer_name\", \"\"),\n",
    "            \"application_link\" : job.get(\"job_apply_link\", \"\"),\n",
    "            \"title\": job.get(\"job_title\", \"\")\n",
    "        }\n",
    "        \n",
    "        documents.append(Document(page_content=text, metadata=metadata))\n",
    "    \n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "66a9b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_id': '1KrlXuQgUYO3vXs6AAAAAA==', 'company': 'Illumina', 'application_link': 'https://in.linkedin.com/jobs/view/data-scientist-%E2%80%93-ml-ai-systems-at-illumina-4282143418?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'title': 'Data Scientist â€“ ML / AI-Systems'}\n",
      "Job Title: Data Scientist â€“ ML / AI-Systems\n",
      "Company: Illumina\n",
      "Location: None, IN\n",
      "Description: What if the work you did every day could impact the lives of people you know? Or all of humanity?\n",
      "\n",
      "At Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients.\n",
      "\n",
      "Working at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world changing projects, you will do more and become more than you ever thought possible.\n",
      "\n",
      "Position Summary\n",
      "\n",
      "We are seeking a talented and driven Data Scientist to join our dynamic team at Illumina. In this role, you will collaborate with cross-functional teams of scientists, engineers, and bioinformaticians to analyze complex biological data, develop advanced models, and deliver actionable insights that propel Illuminaâ€™s research, development, and commercial objectives. Your work will directly support initiatives across genomics, clinical applications, and product development, helping to shape the future of personalized medicine and health care.\n",
      "\n",
      "Key Responsibilities\n",
      "â€¢ Design, develop, and implement robust statistical models, machine learning algorithms, and analytical pipelines.\n",
      "â€¢ Partner with internal teamsâ€”including research, product, informatics, and engineeringâ€”to define project goals, data needs, and analytical approaches that align with Illuminaâ€™s strategic objectives.\n",
      "â€¢ Apply data mining and predictive modeling techniques to identify patterns, trends, and correlations in diverse datasets (e.g., sequencing data, clinical outcomes, operational metrics).\n",
      "â€¢ Evaluate and validate model performance, ensuring reproducibility, scalability, and reliability of analytical solutions.\n",
      "â€¢ Collaborate with software engineers to deploy analytical tools and integrate models into production-grade software platforms for internal and customer-facing applications.\n",
      "â€¢ Communicate complex data-driven findings clearly and effectively to both technical and non-technical stakeholders through presentations, documentation, and visualizations.\n",
      "â€¢ Stay current with emerging trends, tools, and best practices in data science, machine learning, and computational biology; continuously seek opportunities to improve processes and outcomes.\n",
      "â€¢ Contribute to the publication and dissemination of results in peer-reviewed journals, conferences, and internal reports as appropriate.\n",
      "â€¢ Collaborate with AI-systems designers to implement LLM driven solutions in support of enterprise use cases (LLM driven chatbots)\n",
      "\n",
      "Required Qualifications\n",
      "â€¢ Education: Bachelorâ€™s degree in Data Science, Computer Science, Statistics, Mathematics, Bioinformatics, Computational Biology, Engineering, or a closely related field. Masterâ€™s degree or Ph.D. is preferred.\n",
      "â€¢ Proven experience working with large and complex datasets, with a strong background in data wrangling, statistical analysis, and machine learning.\n",
      "â€¢ Demonstrated proficiency in at least one major programming language used for data analysis (such as Python, R, or Julia).\n",
      "â€¢ Experience with cloud computing platforms, including AWS, MS Azure, as well as modern data warehousing solutions such as Snowflake.\n",
      "â€¢ Familiarity with enterprise data management / data processing tools â€“ Kubernetes, Tableau, Apache\n",
      "â€¢ Understanding of version control systems, especially Git, for collaborative code development and review.\n",
      "â€¢ Excellent communication skills, including the ability to translate technical findings into actionable recommendations for diverse audiences.\n",
      "â€¢ Analytical mindset and a passion for problem-solving in an interdisciplinary, fast-paced environment.\n",
      "â€¢ Self-motivated, detail-oriented, and able to manage multiple projects concurrently with minimal supervision.\n",
      "\n",
      "Preferred Qualifications\n",
      "â€¢ Masterâ€™s degree or Ph.D. in a relevant field (Bioinformatics, Computational Biology, Data Science, etc.).\n",
      "â€¢ Typically requires a Bachelorâ€™s degree and a minimum of 2 years of related experience; or an advanced degree without experience; or equivalent work experience\n",
      "â€¢ Hands-on experience with genomic data analysis, including familiarity with next-generation sequencing (NGS) platforms, omics data types, and relevant bioinformatics tools.\n",
      "â€¢ History of contributing to open-source projects or publications in scientific journals.\n",
      "â€¢ Experience working in highly regulated environments and understanding of data privacy standards (e.g., HIPAA, GDPR) as applied to biological and clinical data.\n",
      "â€¢ Background in healthcare, life sciences, or biotechnology industry.\n",
      "\n",
      "Key Skills and Competencies\n",
      "â€¢ Strong foundation in statistics, probability, and experimental design.\n",
      "â€¢ Expertise in supervised and unsupervised machine learning techniques (e.g., regression, classification, clustering, dimensionality reduction).\n",
      "â€¢ Comfortable working in a regulated environment and managing code, solution designs within these constraints.\n",
      "â€¢ Proficiency in data cleaning, preprocessing, and feature engineering for structured and unstructured data.\n",
      "â€¢ Ability to assess and select appropriate models, evaluate metrics, and iterate solutions using best practices.\n",
      "â€¢ Capacity to work collaboratively in multidisciplinary teams and adapt to evolving project requirements.\n",
      "â€¢ Innovative thinker with a desire to apply data science solutions to real-world challenges.\n",
      "\n",
      "We are a company deeply rooted in belonging, promoting an inclusive environment where employees feel valued and empowered to contribute to our mission. Built on a strong foundation, Illumina has always prioritized openness, collaboration, and seeking alternative perspectives to propel innovation in genomics. We are proud to confirm a zero-net gap in pay, regardless of gender, ethnicity, or race. We also have several Employee Resource Groups (ERG) that deliver career development experiences, increase cultural awareness, and offer opportunities to engage in social responsibility. We are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. Illumina conducts background checks on applicants for whom a conditional offer of employment has been made. Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable local, state, and federal laws. Background check results may potentially result in the withdrawal of a conditional offer of employment. The background check process and any decisions made as a result shall be made in accordance with all applicable local, state, and federal laws. Illumina prohibits the use of generative artificial intelligence (AI) in the application and interview process. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. The position will be posted until a final candidate is selected or the requisition has a sufficient number of qualified applicants. This role is not eligible for visa sponsorship.\n",
      "Qualifications: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunks= jobs_to_documents(result)\n",
    "\n",
    "print(chunks[0].metadata)\n",
    "print(chunks[0].page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fee9772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\vishnu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\vishnu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from faiss-cpu) (2.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vishnu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from faiss-cpu) (25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca6d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishnu\\AppData\\Local\\Temp\\ipykernel_24284\\3111708174.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\Vishnu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Vishnu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector store with open-source embeddings created.\n"
     ]
    }
   ],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Initialize Hugging Face Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create vector store from your documents (pipe)\n",
    "vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# Save to disk\n",
    "vectorstore.save_local(\"faiss_job_index_miniLM\")\n",
    "\n",
    "print(\"âœ… Vector store with open-source embeddings created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c809ca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors stored: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of vectors stored: {vectorstore.index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c418df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embedding = embedding_model.embed_documents([resume_text])[0]  # embedding for the single resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9dcd9d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.019949015229940414,\n",
       " -0.049315374344587326,\n",
       " 0.0061637782491743565,\n",
       " 0.03824648633599281,\n",
       " -0.004889398347586393,\n",
       " -0.10756099224090576,\n",
       " -0.019468829035758972,\n",
       " -0.018926432356238365,\n",
       " -0.10029670596122742,\n",
       " 0.0019442157354205847,\n",
       " -0.03439478203654289,\n",
       " -0.07810977101325989,\n",
       " 0.0037277303636074066,\n",
       " -0.05276336520910263,\n",
       " -0.032647501677274704,\n",
       " 0.030067240819334984,\n",
       " -0.014305366203188896,\n",
       " -0.03888386860489845,\n",
       " 0.05836031585931778,\n",
       " -0.12143193930387497,\n",
       " -0.04146502539515495,\n",
       " 0.01896439678966999,\n",
       " 0.03898094967007637,\n",
       " -0.06491297483444214,\n",
       " 0.06927408277988434,\n",
       " -0.05489130690693855,\n",
       " 0.024474972859025,\n",
       " 0.012507434003055096,\n",
       " -0.060687821358442307,\n",
       " -0.054814692586660385,\n",
       " -0.11869604140520096,\n",
       " 0.015081406570971012,\n",
       " 0.0019634137861430645,\n",
       " 0.09731293469667435,\n",
       " 0.0026715686544775963,\n",
       " 0.026639923453330994,\n",
       " 0.040310487151145935,\n",
       " 0.004855215549468994,\n",
       " 0.04446154832839966,\n",
       " 0.03349852189421654,\n",
       " -0.029441628605127335,\n",
       " -0.059460852295160294,\n",
       " -0.022688213735818863,\n",
       " -0.04734398052096367,\n",
       " 0.039149198681116104,\n",
       " -0.03407944738864899,\n",
       " -0.061221037060022354,\n",
       " -0.11639856547117233,\n",
       " 0.04213195666670799,\n",
       " 0.02452917955815792,\n",
       " -0.1192447617650032,\n",
       " -0.06314767897129059,\n",
       " -0.056770212948322296,\n",
       " 0.012350318022072315,\n",
       " -0.005284763406962156,\n",
       " 0.011802354827523232,\n",
       " 0.03592175245285034,\n",
       " -0.02703053131699562,\n",
       " 0.017260637134313583,\n",
       " -0.07782696932554245,\n",
       " -0.036129701882600784,\n",
       " -0.005165955517441034,\n",
       " -0.038897816091775894,\n",
       " 0.06878630071878433,\n",
       " -0.0105957156047225,\n",
       " -0.018320433795452118,\n",
       " -0.05794570967555046,\n",
       " 0.08818092942237854,\n",
       " 0.03286759927868843,\n",
       " -0.05963846296072006,\n",
       " 0.0010514425812289119,\n",
       " -0.03205617517232895,\n",
       " -0.0811968520283699,\n",
       " 0.07220395654439926,\n",
       " 0.03276057168841362,\n",
       " -0.04129176586866379,\n",
       " 0.04088476672768593,\n",
       " -0.0011897372314706445,\n",
       " 0.06916441768407822,\n",
       " 0.025381261482834816,\n",
       " -0.07850822806358337,\n",
       " -0.007342356722801924,\n",
       " -0.046398766338825226,\n",
       " 0.06250599026679993,\n",
       " -0.0471159890294075,\n",
       " -0.07363913953304291,\n",
       " -0.024603400379419327,\n",
       " 0.044180527329444885,\n",
       " 0.03211233764886856,\n",
       " -0.009030826389789581,\n",
       " 0.0649523138999939,\n",
       " -0.04459868371486664,\n",
       " 0.03989803418517113,\n",
       " 0.08544667810201645,\n",
       " -0.03257611766457558,\n",
       " 0.009632487781345844,\n",
       " 0.02531278133392334,\n",
       " -0.02353387139737606,\n",
       " 0.024620767682790756,\n",
       " 0.03467226028442383,\n",
       " -0.03373036906123161,\n",
       " -0.037151090800762177,\n",
       " 0.029854057356715202,\n",
       " 0.03754503279924393,\n",
       " -0.09886880964040756,\n",
       " 0.03763020038604736,\n",
       " 0.027613457292318344,\n",
       " -0.02262512780725956,\n",
       " 0.07928557693958282,\n",
       " 0.00036158779403194785,\n",
       " -0.013412515632808208,\n",
       " 0.006916595157235861,\n",
       " -0.13420610129833221,\n",
       " -0.0725562572479248,\n",
       " -0.012179188430309296,\n",
       " 0.07415584474802017,\n",
       " -0.06658969819545746,\n",
       " 0.046427953988313675,\n",
       " -0.000417216622736305,\n",
       " 0.06833485513925552,\n",
       " -0.028215663507580757,\n",
       " 0.08782888948917389,\n",
       " -0.06844288855791092,\n",
       " -0.08216608315706253,\n",
       " -0.019698480144143105,\n",
       " -0.07333050668239594,\n",
       " -0.060495130717754364,\n",
       " 3.625719020247249e-33,\n",
       " 0.0036712277214974165,\n",
       " -0.0024680246133357286,\n",
       " 0.05932438001036644,\n",
       " -0.01886373944580555,\n",
       " 0.04214400798082352,\n",
       " -0.013983776792883873,\n",
       " 0.007278754375874996,\n",
       " 0.0419224351644516,\n",
       " -0.05182274430990219,\n",
       " 0.040241796523332596,\n",
       " -0.041653599590063095,\n",
       " 0.13411526381969452,\n",
       " -0.07913932204246521,\n",
       " 0.05979112908244133,\n",
       " 0.023454051464796066,\n",
       " 0.03185916319489479,\n",
       " 0.021477986127138138,\n",
       " 0.035685066133737564,\n",
       " -0.06745511293411255,\n",
       " 0.055922482162714005,\n",
       " 0.05477093905210495,\n",
       " 0.003953960724174976,\n",
       " -0.021535487845540047,\n",
       " 0.02966122515499592,\n",
       " 0.009946569800376892,\n",
       " 0.018864180892705917,\n",
       " 0.012346187606453896,\n",
       " -0.004965704865753651,\n",
       " 0.045877352356910706,\n",
       " 0.04159863293170929,\n",
       " -0.05287826433777809,\n",
       " -0.0071763829328119755,\n",
       " -0.08407604694366455,\n",
       " -0.05808188393712044,\n",
       " 0.04712698608636856,\n",
       " 0.009186147712171078,\n",
       " -0.041114311665296555,\n",
       " -0.050536494702100754,\n",
       " 0.01994260400533676,\n",
       " 0.008008486591279507,\n",
       " -0.07537651062011719,\n",
       " 0.02105254866182804,\n",
       " 0.01814378798007965,\n",
       " -0.02877095527946949,\n",
       " -0.0008314356673508883,\n",
       " 0.020676692947745323,\n",
       " 0.07466495037078857,\n",
       " 0.030042627826333046,\n",
       " 0.1102682501077652,\n",
       " 0.08127981424331665,\n",
       " -0.13846775889396667,\n",
       " -0.08369341492652893,\n",
       " 0.015454543754458427,\n",
       " 0.030310682952404022,\n",
       " 0.00932573527097702,\n",
       " 0.11255282908678055,\n",
       " 0.08716090768575668,\n",
       " 0.027700092643499374,\n",
       " -0.04570571705698967,\n",
       " -0.0050992160104215145,\n",
       " -0.04047980159521103,\n",
       " 0.00047706335317343473,\n",
       " 0.0002204728516517207,\n",
       " -0.07009907066822052,\n",
       " -0.059443697333335876,\n",
       " -0.001848164713010192,\n",
       " -0.024708475917577744,\n",
       " 0.04494718089699745,\n",
       " 0.13208571076393127,\n",
       " -0.006915502715855837,\n",
       " -0.07982877641916275,\n",
       " 0.04086378961801529,\n",
       " 0.048274021595716476,\n",
       " 0.030620640143752098,\n",
       " 0.03964252397418022,\n",
       " 0.0022622300311923027,\n",
       " 0.0007514323806390166,\n",
       " -0.034679289907217026,\n",
       " -0.026457900181412697,\n",
       " 0.0069664353504776955,\n",
       " -0.013305130414664745,\n",
       " -0.01871541142463684,\n",
       " -0.04767638072371483,\n",
       " -0.06210968270897865,\n",
       " 0.03368702903389931,\n",
       " 0.0677959993481636,\n",
       " 0.047216251492500305,\n",
       " -0.029960211366415024,\n",
       " -0.019323062151670456,\n",
       " -0.016363784670829773,\n",
       " -0.09213234484195709,\n",
       " 0.049867600202560425,\n",
       " 0.021762186661362648,\n",
       " 0.03888298198580742,\n",
       " -0.10198630392551422,\n",
       " -6.235027013588838e-33,\n",
       " -0.022324316203594208,\n",
       " -0.0010055641178041697,\n",
       " -0.053500737994909286,\n",
       " 0.060989588499069214,\n",
       " 0.11374808102846146,\n",
       " 0.0611746646463871,\n",
       " 0.07423118501901627,\n",
       " -0.014119924046099186,\n",
       " 0.03348632901906967,\n",
       " -0.015352019108831882,\n",
       " -0.021120302379131317,\n",
       " -0.01126568578183651,\n",
       " 0.04582689702510834,\n",
       " -0.0012146818917244673,\n",
       " 0.0011400151997804642,\n",
       " 0.05360902473330498,\n",
       " -0.0950702354311943,\n",
       " 0.0069343396462500095,\n",
       " -0.13495290279388428,\n",
       " 0.03620005026459694,\n",
       " -0.035243045538663864,\n",
       " 0.07192454487085342,\n",
       " -0.08972731232643127,\n",
       " 0.03706951439380646,\n",
       " 0.07319486886262894,\n",
       " -0.04310499131679535,\n",
       " -0.07727757096290588,\n",
       " -0.03193698450922966,\n",
       " -0.01637757383286953,\n",
       " 0.028127038851380348,\n",
       " -0.02786649391055107,\n",
       " 0.0512402206659317,\n",
       " -0.04612135514616966,\n",
       " 0.05440618470311165,\n",
       " -0.018905242905020714,\n",
       " -0.06847399473190308,\n",
       " 0.08289740979671478,\n",
       " -0.04355460777878761,\n",
       " 0.01696684956550598,\n",
       " 0.0792735144495964,\n",
       " 0.04551680013537407,\n",
       " -0.01032677199691534,\n",
       " -0.0002632003161124885,\n",
       " 0.014291013590991497,\n",
       " -0.012423286214470863,\n",
       " -0.030605411157011986,\n",
       " -0.0023904531262815,\n",
       " 0.041114892810583115,\n",
       " 0.020284267142415047,\n",
       " -0.037175253033638,\n",
       " -0.013239617459475994,\n",
       " 0.06169098615646362,\n",
       " -0.023704050108790398,\n",
       " 0.031936533749103546,\n",
       " 0.04168492928147316,\n",
       " -0.012381037697196007,\n",
       " 0.02820696495473385,\n",
       " -0.005372385960072279,\n",
       " -0.06702306866645813,\n",
       " -0.02631962113082409,\n",
       " -0.04337029904127121,\n",
       " 0.01311149075627327,\n",
       " 0.07484987378120422,\n",
       " 0.07934706658124924,\n",
       " 0.008598553948104382,\n",
       " -0.09134849905967712,\n",
       " -0.0672149583697319,\n",
       " 0.04766862839460373,\n",
       " -0.09449349343776703,\n",
       " -0.09747567027807236,\n",
       " 0.0062356735579669476,\n",
       " 0.03712175041437149,\n",
       " 0.03995048999786377,\n",
       " -0.07284591346979141,\n",
       " -0.05398661643266678,\n",
       " -0.017790425568819046,\n",
       " -0.05025302618741989,\n",
       " -0.04181932657957077,\n",
       " -0.05261639878153801,\n",
       " 0.04942232370376587,\n",
       " 0.022312521934509277,\n",
       " -0.008764891885221004,\n",
       " 0.014960779808461666,\n",
       " 0.1413164883852005,\n",
       " 0.007976124063134193,\n",
       " 0.06235523149371147,\n",
       " 0.057890746742486954,\n",
       " -0.035686299204826355,\n",
       " 0.03637490049004555,\n",
       " -0.04714471846818924,\n",
       " -0.06040114164352417,\n",
       " 0.011966215446591377,\n",
       " -0.019041895866394043,\n",
       " 0.06260082125663757,\n",
       " -0.036058757454156876,\n",
       " -5.101920308447916e-08,\n",
       " -0.045415446162223816,\n",
       " 0.014976123347878456,\n",
       " -0.04032401740550995,\n",
       " 0.035985011607408524,\n",
       " 0.060308437794446945,\n",
       " -0.004811657126992941,\n",
       " -0.0534035861492157,\n",
       " 0.07173946499824524,\n",
       " -0.03678533807396889,\n",
       " 0.0059873079881072044,\n",
       " 0.04975809156894684,\n",
       " -0.03519108146429062,\n",
       " -0.06311358511447906,\n",
       " -0.004878241568803787,\n",
       " 0.06821516901254654,\n",
       " 0.031224874779582024,\n",
       " 0.029836121946573257,\n",
       " 0.06933736056089401,\n",
       " 0.0066740973852574825,\n",
       " -0.03662397712469101,\n",
       " 0.05584026128053665,\n",
       " -0.019843675196170807,\n",
       " -0.043731581419706345,\n",
       " 0.08395536243915558,\n",
       " -0.025096364319324493,\n",
       " -0.03700334206223488,\n",
       " -0.05818783491849899,\n",
       " 0.0002701597986742854,\n",
       " 0.014139962382614613,\n",
       " 0.031366508454084396,\n",
       " -0.05087052285671234,\n",
       " -0.04636446759104729,\n",
       " 0.020697513595223427,\n",
       " -0.09747146815061569,\n",
       " 0.07322376221418381,\n",
       " 0.030862879008054733,\n",
       " 0.04831862822175026,\n",
       " -0.04815291613340378,\n",
       " -0.01324559561908245,\n",
       " 0.08696293830871582,\n",
       " -0.03995372727513313,\n",
       " -0.015595977194607258,\n",
       " 3.533899143803865e-05,\n",
       " 0.018475767225027084,\n",
       " 0.011997560039162636,\n",
       " 0.03162851929664612,\n",
       " -0.03703918680548668,\n",
       " 0.0002552835503593087,\n",
       " 0.04252707585692406,\n",
       " 0.010030488483607769,\n",
       " 0.0004229523765388876,\n",
       " -0.04194296896457672,\n",
       " -0.055062055587768555,\n",
       " 0.004028382245451212,\n",
       " 0.06216807663440704,\n",
       " 0.11850008368492126,\n",
       " -0.025310121476650238,\n",
       " -0.04053742438554764,\n",
       " -0.043603282421827316,\n",
       " 0.0019658254459500313,\n",
       " 0.11228200048208237,\n",
       " -0.03628184273838997,\n",
       " -0.011032593436539173,\n",
       " 0.04454236850142479]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vector store (already created)\n",
    "vectorstore = FAISS.load_local(\"faiss_job_index_miniLM\", embedding_model, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e079dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform similarity search with the resume embedding\n",
    "# This will return the most similar job documents to your resume\n",
    "search_results = vectorstore.similarity_search_by_vector(resume_embedding, k=5)  # top 5 most similar jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2385b108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='04f75a55-68ae-4d2d-a5fe-a81f680da90d', metadata={'job_id': 'rTT459fizvKKYqSIAAAAAA==', 'company': 'DataU Technologies', 'application_link': 'https://datautechnologies.freshteam.com/jobs/X84Jkgl1bF3o/data-analyst-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'title': 'Data Analyst / Data Scientist'}, page_content='Job Title: Data Analyst / Data Scientist\\nCompany: DataU Technologies\\nLocation: Nagpur, IN\\nDescription: Job role:\\n\\nAs a data analyst, you will be responsible for compiling actionable insights from data and assisting program, sales, and marketing managers build data-driven processes. Your role will involve driving initiatives to optimize for operational excellence and revenue.\\n\\nResponsibilities:\\nâ€¢ Ensure that data flows smoothly from source to destination so that it can be processed\\nâ€¢ Utilize strong database skills to work with large, complex data sets to extract insights\\nâ€¢ Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes\\nâ€¢ Identify new internal and external data sources to support analytics initiatives and work with appropriate partners to absorb the data into new or existing data infrastructure\\nâ€¢ Build tools for automating repetitive tasks so that bandwidth can be freed for analytics\\nâ€¢ Collaborate with program managers and business analysts to help them come up with actionable, high-impact insights across product lines and functions\\nâ€¢ Work closely with top management to prioritize information and analytic needs\\n\\nRequirements:\\nâ€¢ Bachelors or Masters in a quantitative field (such as Engineering, Statistics, Math, Economics, or Computer Science with Modeling/Data Science).\\nâ€¢ The ability to program in any high-level language is required. Familiarity with R and statistical packages is preferred.\\nâ€¢ Proven problem-solving and debugging skills.\\nâ€¢ Familiar with database technologies and tools (SQL/R/SAS/JMP etc.), data warehousing, transformation, and processing. Work experience with real data for customer insights, business, and market analysis will be advantageous.\\nâ€¢ Experience with text analytics, data mining, and social media analytics.\\nâ€¢ Statistical knowledge in standard techniques: Logistic Regression, Classification models, Cluster Analysis, Neural Networks, Random Forests, Ensembles, etc.\\nQualifications: \\n'),\n",
       " Document(id='f53c3231-8b6f-457a-aa9a-381934425af5', metadata={'job_id': 'GF2xIEGT6wE8lirfAAAAAA==', 'company': 'Hitech Digital Solutions', 'application_link': 'https://in.jooble.org/rjdp/-6430160667946787041?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'title': 'Senior Data Scientist - Machine Learning, AI'}, page_content=\"Job Title: Senior Data Scientist - Machine Learning, AI\\nCompany: Hitech Digital Solutions\\nLocation: Ahmedabad, IN\\nDescription: Data Scientist Location: Office-Based (Ahmedabad, India)\\n\\nHitech is a leading provider of Data, Engineering Services, and Business Process Solutions. With robust delivery centers in India and global sales offices in the USA, UK, and the Netherlands, we enable digital transformation for clients across industries including Manufacturing, Real Estate, and e-Commerce.\\n\\nOur Data Solutions practice integrates automation, digitalization, and outsourcing to deliver measurable business outcomes. As we continue expanding, weâ€™re looking for a skilled Lead Data Scientist to guide innovation, lead teams, and solve complex problems using advanced analytics and machine learning.\\n\\nAs a Lead Data Scientist, you will lead a team of data scientists, machine learning engineers, and big data specialists to design, develop, and deploy data-driven solutions. You will be responsible for identifying business opportunities, translating them into data strategies, and driving measurable outcomes. Manage a team of data scientists, machine learning engineers, and big data specialists.\\nLead data mining, data collection, and cleansing procedures.\\nEnsure high standards of data quality and integrity across all projects.\\nInterpret complex data sets to identify patterns, trends, and actionable insights.\\nConceive, plan, and prioritize data science initiatives aligned with business goals.\\nTest and validate data-driven products for performance and reliability.\\nExperiment with emerging models and machine learning techniques for innovation.\\n\\nQualifications & Experience\\nâ€¢ 6-8 years of working experience in Image Processing using deep learning frameworks such as OpenCV, PyTorch, TensorFlow, Theano, and Caffe.\\nâ€¢ Experience in Text Analytics using NLP tools and techniques on unstructured data.\\nâ€¢ Proven track record in building, deploying, and scaling statistical and deep learning models.\\nâ€¢ Experience with large-scale data (structured and unstructured), data management, parallel computing, and distributed systems.\\nâ€¢ Ability to thrive with minimal supervision in a dynamic, fast-paced environment.\\nâ€¢ Capability to understand diverse business processes and quickly contextualize data requirements.\\nâ€¢ Strong problem-solving skills to translate business problems into actionable data strategies.\\nâ€¢ Strong passion for leveraging AI/ML to solve business problems and a proactive approach to experimentation.\\nâ€¢ Hands-on experience with exploratory data analysis, machine learning, and advanced analytics methods.\\n\\nCompetitive compensation based on skills and experience.\\nLeadership role in building and scaling AI/ML initiatives.\\nOpportunity to work on high-impact global projects with cutting-edge technologies.\\nContinuous learning, innovation, and professional development support.\\nIf you're passionate about driving innovation through data and leading a dynamic team to solve real-world problems, weâ€™d love to hear from you.\\n\\nHitech Digital Solutions\\nQualifications: \\n\"),\n",
       " Document(id='392ee12e-d566-49f3-99ac-1c3c8400d5e8', metadata={'job_id': '8ikGDWpNlhIhnTkPAAAAAA==', 'company': 'Infilon Technologies Pvt ltd', 'application_link': 'https://in.linkedin.com/jobs/view/sr-data-engineer-neo4j-graph-data-science-at-infilon-technologies-pvt-ltd-4279887236?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'title': 'Sr. Data Engineer - Neo4j Graph Data Science'}, page_content=\"Job Title: Sr. Data Engineer - Neo4j Graph Data Science\\nCompany: Infilon Technologies Pvt ltd\\nLocation: Ahmedabad, IN\\nDescription: Infilon Technologies is a prominent software development company located in Ahmedabad, is hiring a Senior Data Engineer with deep expertise in Neo4j Graph Data Science. You'll work on large, complex datasets, leveraging advanced mathematics and search techniques to build intelligent, scalable solutions.\\n\\nJob Location: Ahmedabad, Gujarat (Work from Office)\\n\\nExperience: 5+ Years\\n\\nKey Responsibilities\\nâ€¢ Architect, develop, and optimize data models using Neo4j or other graph databases.\\nâ€¢ Apply graph-based data science algorithms, including centrality, community detection, and link prediction, using Neo4j GDS.\\nâ€¢ Design and implement advanced search and traversal algorithms for complex data structures.\\nâ€¢ Work on large-scale, highly interconnected datasets to uncover patterns, insights, and business value.\\nâ€¢ Use your mathematical expertise to solve algorithmic and analytical challenges.\\nâ€¢ Collaborate with cross-functional teams to integrate graph-based intelligence into scalable software systems.\\nâ€¢ Stay updated with the latest advancements in graph data science, AI, and related technologies.\\nâ€¢ A quick learner with a proven ability to be adaptive to new technologies and evolving project requirements.\\nâ€¢ Exceptional analytical and problem-solving skills with a keen attention to detail.\\nâ€¢ Excellent communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.\\n\\nRequired Skills\\nâ€¢ 5+ years in data science or architecture roles.\\nâ€¢ Strong hands-on with Neo4j and Cypher.\\nâ€¢ Solid background in mathematics and graph theory.\\nâ€¢ Experience with search algorithms and data science workflows.\\nâ€¢ Proficient in Python and relevant ML libraries.\\n\\nNice to Have\\nâ€¢ Experience with machine learning frameworks (e.g., scikit-learn, TensorFlow, PyTorch).\\nâ€¢ Exposure to distributed computing frameworks (e.g., Spark, Hadoop).\\nâ€¢ Knowledge of knowledge graphs and semantic modeling.\\nâ€¢ Prior experience in architect-level roles in data-driven product teams.\\nâ€¢ Understanding of electrical components.\\nQualifications: \\n\"),\n",
       " Document(id='e4953d22-3239-4267-99c3-a1e80bf666a9', metadata={'job_id': 's9ujTov2FTXozowwAAAAAA==', 'company': 'confidential', 'application_link': 'https://in.jooble.org/jdp/-3732140163632509115?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'title': 'Gen AI | ML- Data Scientist- ( Lead) -Mum/chennai'}, page_content='Job Title: Gen AI | ML- Data Scientist- ( Lead) -Mum/chennai\\nCompany: confidential\\nLocation: Secunderabad, IN\\nDescription: we are driven to deliver service excellence and quality is the center of every project. With team of more than 75 eminent data scientists, Our client provides advanced AI-based customized solutions, big data infrastructure development and integration services, predictive analytics and machine learning technologies, and corporate training in big data analytics. Typically, our project life cycle entails:\\nWe follow comprehensive testing before the solution is deployed in the production environment. There are components of solution which ensure that identified stakeholders are alerted when system reports a confidence level lower than benchmark. These alerts can be sent via email or other real-time notifications.\\n\\nThis role is responsible for managing the client expectations. Strategize with various stakeholders to meet customer requirements.\\nKEY RESPONSIBILITIES\\nData Science: Develop machine learning models to support recommendation systems and NLP projects provide actionable insights for product and service optimization.\\nData Engineering: Build and maintain scalable ETL pipelines, optimize data storage solutions (data lakes, columnar formats), and ensure data accuracy for analytics.\\nData Analysis and Insight Generation: Skilled in analyzing complex datasets to uncover trends and patterns generate and present insights that drive strategic decisions and enhance client services.\\nStakeholder Collaboration: Work with product and service teams to understand data needs and translate them into technical solutions.\\n\\nWorking Relationships\\nReporting to Project Manager\\nExternal Stakeholders Clients\\n\\nSkills/ Competencies Required\\nTechnical Skills Proficiency with Python (Pandas, NumPy), SQL, and Java.\\nExperience with LLMs, LangChain, and Generative AI technologies.\\nFamiliarity with ML frameworks (TensorFlow, PyTorch) and data engineering tools (Spark, Kafka).\\nMicroservices, CI CD, ML\\nStrong data analysis skills and ability to present findings to both technical and non-technical stakeholders.\\nProficient understanding of key data engineering concepts, such as data lakes, columnar formats, ETL tools, and BI tools.\\nKnowledge in Machine Learning, NLP, Recommender systems, personalization, Segmentation, microservices architecture and API development.\\nAbility to adapt to a fast-paced, dynamic work environment and learn new technologies quickly.\\n\\nSoft Skills Work in a team/ Independently.\\nExcellent Written & Verbal Communication Skills\\nSolid critical thinking and questioning skills.\\nHigh degree of flexibility - willing to fill in the gaps rather than relying on others\\nStrong communication skills, especially in presenting data insights.\\nFlexibility, problem-solving, and a proactive approach in a fast-paced environment\\nQualifications: \\n'),\n",
       " Document(id='2fdcf567-5793-4190-b3bc-d3ba8975745f', metadata={'job_id': 'pntLQJcdmbktGXiZAAAAAA==', 'company': 'Guidehouse', 'application_link': 'https://in.linkedin.com/jobs/view/lead-data-scientist-ai-at-guidehouse-4282101098?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'title': 'Lead - Data Scientist & AI'}, page_content='Job Title: Lead - Data Scientist & AI\\nCompany: Guidehouse\\nLocation: Thiruvananthapuram, IN\\nDescription: Job Family\\n\\nData Science & Analysis (India)\\n\\nTravel Required\\n\\nUp to 10%\\n\\nClearance Required\\n\\nNone\\n\\nWhat You Will Do\\nâ€¢ Design, train, and fine-tune advanced foundational models (text, audio, vision) using healthcare-and other relevant datasets, focusing on accuracy and context relevance.\\nâ€¢ Collaborate with cross-functional teams (Business, engineering, IT) to seamlessly integrate AI/ML technologies into our solution offerings.\\nâ€¢ Deploy, monitor, and manage AI models in a production environment, ensuring high availability, scalability, and performance.\\nâ€¢ Continuously research and evaluate the latest advancements in AI/ML and industry trends to drive innovation.\\nâ€¢ Develop and maintain comprehensive documentation for AI models, including development, training, fine-tuning, and deployment procedures.\\nâ€¢ Provide technical guidance and mentorship to junior AI engineers and team members.\\nâ€¢ Collaborate with stakeholders to understand business needs and translate them into technical requirements for model fine-tuning and development.\\nâ€¢ Select and curate appropriate datasets for fine-tuning foundational models to address specific use cases.\\nâ€¢ Ensure AI solutions can seamlessly integrate with existing systems and applications.\\n\\nWhat You Will Need\\nâ€¢ Bachelors or masterâ€™s in computer science, Artificial Intelligence, Machine Learning, or a related field.\\nâ€¢ 4 to 6 years of hands-on experience in AI/ML, with a demonstrable track record of training and deploying LLMs and other machine learning models.\\nâ€¢ Strong proficiency in Python and familiarity with popular AI/ML frameworks (TensorFlow, PyTorch, Hugging Face Transformers, etc.).\\nâ€¢ Practical experience deploying and managing AI models in production environments, including expertise in serving and inference frameworks (Triton, TensorRT, VLLM, TGI, etc.).\\nâ€¢ Experience in Voice AI applications, a solid understanding of healthcare data standards (FHIR, HL7, EDI) and regulatory compliance (HIPAA, SOC2) is preferred.\\nâ€¢ Excellent problem-solving and analytical abilities, capable of tackling complex challenges and evaluating multiple factors.\\nâ€¢ Exceptional communication and collaboration skills, enabling effective teamwork in a dynamic environment.\\nâ€¢ Worked on a minimum of 2 AI/LLM projects from the beginning to the end with proven value for business.\\n\\nWhat Would Be Nice To Have\\nâ€¢ Experience with cloud computing platforms (AWS, Azure) and containerization technologies (Docker, Kubernetes) is a plus.\\nâ€¢ Familiarity with MLOps practices for continuous integration, continuous deployment (CI/CD), and automated monitoring of AI models.\\n\\nWhat We Offer\\n\\nGuidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace.\\n\\nAbout Guidehouse\\n\\nGuidehouse is an Equal Opportunity Employerâ€“Protected Veterans, Individuals with Disabilities or any other basis protected by law, ordinance, or regulation.\\n\\nGuidehouse will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law or ordinance including the Fair Chance Ordinance of Los Angeles and San Francisco.\\n\\nIf you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting at 1-571-633-1711 or via email at RecruitingAccommodation@guidehouse.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation.\\n\\nAll communication regarding recruitment for a Guidehouse position will be sent from Guidehouse email domains including @guidehouse.com or guidehouse@myworkday.com. Correspondence received by an applicant from any other domain should be considered unauthorized and will not be honored by Guidehouse. Note that Guidehouse will never charge a fee or require a money transfer at any stage of the recruitment process and does not collect fees from educational institutions for participation in a recruitment event. Never provide your banking information to a third party purporting to need that information to proceed in the hiring process.\\n\\nIf any person or organization demands money related to a job opportunity with Guidehouse, please report the matter to Guidehouseâ€™s Ethics Hotline. If you want to check the validity of correspondence you have received, please contact recruiting@guidehouse.com. Guidehouse is not responsible for losses incurred (monetary or otherwise) from an applicantâ€™s dealings with unauthorized third parties.\\n\\nGuidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.\\nQualifications: \\n')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9541c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028328B00180>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028328B00B00>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7bf7428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser=JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8659e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You must use ONLY the provided context and return **VALID JSON ONLY** â€” no extra text, no explanation, no formatting outside the JSON.\n",
    "\n",
    "Evaluate each job in the {search_results}.\n",
    "\n",
    "Include a job ONLY if it can be strictly justified using the {extracted_data}. Do NOT include any job unless this condition is met.\n",
    "\n",
    "Do NOT add any skills or reasoning that are not explicitly present in the resume text.\n",
    "\n",
    "If the skills or justification are insufficient, DO NOT include that job.\n",
    "\n",
    "Each included job must match at least 2â€“3 skills from the resume.\n",
    "\n",
    "The JSON output must include ONLY the following fields per job:\n",
    "- Name of the company\n",
    "- Job title\n",
    "- Apply link\n",
    "- Why good fit\n",
    "\n",
    "Return a clean, parsable JSON array only. No markdown. No commentary.\n",
    "\"\"\",\n",
    "    input_variables=['search_results','extracted_data']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3dbf2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c046372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Company': 'DataU Technologies', 'Job Title': 'Data Analyst / Data Scientist', 'Apply Link': 'https://datautechnologies.freshteam.com/jobs/X84Jkgl1bF3o/data-analyst-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'Why good fit': 'The job requires data analysis, data visualization, and machine learning skills, which are listed in the resume.'}, {'Company': 'Hitech Digital Solutions', 'Job Title': 'Senior Data Scientist - Machine Learning, AI', 'Apply Link': 'https://in.jooble.org/rjdp/-6430160667946787041?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'Why good fit': 'The job requires experience in machine learning, data science, and programming languages like Python, which are listed in the resume.'}, {'Company': 'Infilon Technologies Pvt ltd', 'Job Title': 'Sr. Data Engineer - Neo4j Graph Data Science', 'Apply Link': 'https://in.linkedin.com/jobs/view/sr-data-engineer-neo4j-graph-data-science-at-infilon-technologies-pvt-ltd-4279887236?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic', 'Why good fit': 'The job requires experience in data engineering, Neo4j, and graph data science, which are not explicitly listed in the resume but are relevant skills.'}]\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\n",
    "    'search_results' : search_results,\n",
    "    'extracted_data': extracted_data\n",
    "}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
